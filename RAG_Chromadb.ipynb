{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f66191",
   "metadata": {},
   "source": [
    "#### Building RAG Q/A Chatbot Using Langchain,GoogleGenAI and Chromadb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e207457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries \n",
    "from langchain_community.document_loaders import PyPDFLoader \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings \n",
    "from langchain_chroma import Chroma \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145a0c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading doucment \n",
    "loader = PyPDFLoader(\"yolov9_paper.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4cccfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b0942b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv9: Learning What You Want to Learn\n",
      "Using Programmable Gradient Information\n",
      "Chien-Yao Wang1,2, I-Hau Yeh2, and Hong-Yuan Mark Liao1,2,3\n",
      "1Institute of Information Science, Academia Sinica, Taiwan\n",
      "2National Taipei University of Technology, Taiwan\n",
      "3Department of Information and Computer Engineering, Chung Yuan Christian University, Taiwan\n",
      "kinyiu@iis.sinica.edu.tw, ihyeh@emc.com.tw, and liao@iis.sinica.edu.tw\n",
      "Abstract\n",
      "Today’s deep learning methods focus on how to design\n",
      "the most appropriate objective functions so that the pre-\n",
      "diction results of the model can be closest to the ground\n",
      "truth. Meanwhile, an appropriate architecture that can\n",
      "facilitate acquisition of enough information for prediction\n",
      "has to be designed. Existing methods ignore a fact that\n",
      "when input data undergoes layer-by-layer feature extrac-\n",
      "tion and spatial transformation, large amount of informa-\n",
      "tion will be lost. This paper will delve into the important is-\n",
      "sues of data loss when data is transmitted through deep net-\n",
      "works, namely information bottleneck and reversible func-\n",
      "tions. We proposed the concept of programmable gradi-\n",
      "ent information (PGI) to cope with the various changes\n",
      "required by deep networks to achieve multiple objectives.\n",
      "PGI can provide complete input information for the tar-\n",
      "get task to calculate objective function, so that reliable\n",
      "gradient information can be obtained to update network\n",
      "weights. In addition, a new lightweight network architec-\n",
      "ture – Generalized Efficient Layer Aggregation Network\n",
      "(GELAN), based on gradient path planning is designed.\n",
      "GELAN’s architecture confirms that PGI has gained su-\n",
      "perior results on lightweight models. We verified the pro-\n",
      "posed GELAN and PGI on MS COCO dataset based ob-\n",
      "ject detection. The results show that GELAN only uses\n",
      "conventional convolution operators to achieve better pa-\n",
      "rameter utilization than the state-of-the-art methods devel-\n",
      "oped based on depth-wise convolution. PGI can be used\n",
      "for variety of models from lightweight to large. It can be\n",
      "used to obtain complete information, so that train-from-\n",
      "scratch models can achieve better results than state-of-the-\n",
      "art models pre-trained using large datasets, the compari-\n",
      "son results are shown in Figure 1. The source codes are at:\n",
      "https://github.com/WongKinYiu/yolov9.\n",
      "1. Introduction\n",
      "Deep learning-based models have demonstrated far bet-\n",
      "ter performance than past artificial intelligence systems in\n",
      "various fields, such as computer vision, language process-\n",
      "ing, and speech recognition. In recent years, researchers\n",
      "Figure 1. Comparisons of the real-time object detecors on MS\n",
      "COCO dataset. The GELAN and PGI-based object detection\n",
      "method surpassed all previous train-from-scratch methods in terms\n",
      "of object detection performance. In terms of accuracy, the new\n",
      "method outperforms RT DETR [43] pre-trained with a large\n",
      "dataset, and it also outperforms depth-wise convolution-based de-\n",
      "sign YOLO MS [7] in terms of parameters utilization.\n",
      "in the field of deep learning have mainly focused on how\n",
      "to develop more powerful system architectures and learn-\n",
      "ing methods, such as CNNs [21–23, 42, 55, 71, 72], Trans-\n",
      "formers [8, 9, 40, 41, 60, 69, 70], Perceivers [26, 26, 32, 52,\n",
      "56, 81, 81], and Mambas [17, 38, 80]. In addition, some\n",
      "researchers have tried to develop more general objective\n",
      "functions, such as loss function [5, 45, 46, 50, 77, 78], la-\n",
      "bel assignment [10, 12, 33, 67, 79] and auxiliary supervi-\n",
      "sion [18, 20, 24, 28, 29, 51, 54, 68, 76]. The above studies\n",
      "all try to precisely find the mapping between input and tar-\n",
      "get tasks. However, most past approaches have ignored that\n",
      "input data may have a non-negligible amount of informa-\n",
      "tion loss during the feedforward process. This loss of in-\n",
      "formation can lead to biased gradient flows, which are sub-\n",
      "sequently used to update the model. The above problems\n",
      "can result in deep networks to establish incorrect associa-\n",
      "tions between targets and inputs, causing the trained model\n",
      "to produce incorrect predictions.\n",
      "1\n",
      "arXiv:2402.13616v2  [cs.CV]  29 Feb 2024\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51a2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting documents into chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap= 200)\n",
    "docs = text_splitter.split_documents(documents= documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04b206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arter splitting total number of documents\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Embedding vector and store into chroma database \n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"your api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fd64c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key= os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adae90dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05889486148953438,\n",
       " -0.004501754883676767,\n",
       " -0.06729809194803238,\n",
       " -0.012740520760416985,\n",
       " 0.0645611360669136]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = embeddings.embed_query(\"Hello world\")\n",
    "vector[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a1dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c376455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstores = Chroma.from_documents(\n",
    "                                documents= docs,\n",
    "                                embedding = embeddings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16e6b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstores.as_retriever(search_type = \"similarity\", search_kwargs= {\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = \"your api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2405a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create llm model \n",
    "from langchain_groq import ChatGroq \n",
    "llm = ChatGroq(model = \"llama-3.3-70b-versatile\",\n",
    "               api_key = os.environ[\"GROQ_API_KEY\"]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a042f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAG Pipeline \n",
    "\n",
    "\n",
    "#create Prmpt template\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template =  \"\"\"You are an expert assistant tasked with answering questions based on the provided documents.\n",
    "Use only the given context to generate your answer.\n",
    "If the answer cannot be found in the context, clearly state that you do not know.\n",
    "Be detailed and precise in your response, but avoid mentioning or referencing the context itself.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f34a4235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser \n",
    "from langchain_core.runnables import RunnablePassthrough \n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        |rag_prompt\n",
    "        |llm\n",
    "        |StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64d10af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A reversible function refers to a function that has an inverse transformation function. In other words, when a function `r` has an inverse transformation function `v`, it is called a reversible function. This means that the original data `X` can be recovered from the transformed data `rψ(X)` by applying the inverse function `vζ`, without losing any information. The equation `X = vζ(rψ(X))` represents this concept, where `ψ` and `ζ` are parameters of `r` and `v`, respectively.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown \n",
    "\n",
    "response = rag_chain.invoke(\"What is reversible function?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fc1b70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A reversible function refers to a function that has an inverse transformation function. In other words, when a function `r` has an inverse transformation function `v`, it is called a reversible function. This means that the original data `X` can be recovered from the transformed data `rψ(X)` by applying the inverse function `vζ`, without losing any information. The equation `X = vζ(rψ(X))` represents this concept, where `ψ` and `ζ` are parameters of `r` and `v`, respectively."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b139b1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79805945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a4d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0de479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
